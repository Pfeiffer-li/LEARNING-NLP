# 监督式机器学习 之 逻辑回归算法（Logistic Regression Algorithm of Supervised Marching Learning

## 一、整体的理解

        首先，在监督式机器学习中，你有**两个输入**：输入特征集合X 和 集合标签Y。**集合标签Y**可以理解为：它是在你的输入数据的基础上完全准确的预测结果；此有两个特点：第一在你数据的基础上的预测；第二是完全准确的。在监督式机器学习中，我们不对标签集合Y做任何处理，它的任务就是一个 ——“标杆”。**输入特征集合X**可以理解为：就是你的处理数据。

        其次整体的监督式机器学习的过程就是：首先**拿到特征集合X**，然后把特征集合X**投入到预测函数**（prediction function）中运行，在运行过程中我们需要**投入输入参数 $\theta$**，最终也就**获得了模型的预测标签$\widehat{y}$**，然后用开销函数（cost function）**对比预测标签$\widehat{y}$与集合标签Y之间的差异**。这个预测函数的处理过程就是我们的模型处理过程。要想我们的模型的效果不错，需要**对我们的参数进行调整，然后重复上述步骤**，直到得出这个差异的最小值，最后就得到了最佳的模型。这里我们画个图加深理解：

![](../images/supervised%20machine%20learning%20process.jpg)

## 二、用逻辑回归算法去做情感分类用例来演示该监督学习

        首先定义几个点：

        1、首先目标是预测出一组推文中每个推文的情感状态；

        2、情感只包括两个方面：积极方面和消极方面，积极方面的设置为1，消极方面的设置为0；

        3、所以我们首先需要获取输入特征集合X，也就是获取特征，然后在设置参数来一同执行prediction function，然后再执行cost function得出差异，然后不断调参，循环过程，得到最终的模型，也就是逻辑回归分类器。这里是二分类。

## 三、监督学习中的具体实现？

        对逻辑回归分类器（logistic regression classifier）来做情感分析的例子来说：

        **1、第一步：计算机如何能够处理推文？**—— 把推文转化为向量的形式

        首先，你需要**创建一个字典**，这个字典一定包含以下几个**特点**：① 这个字典内容的**维度**是限定在：一个单词；② 这个字典中每个单词是**不可重复**的；③ 这个词典包含这**一组推文**中**所有的**不重复的单词。

```textile
举个例子：一组推文：I am happy because I am learning NLP; ......; I hated that movie.
这组推文中的字典 V = [I, am, happy, because, learning, NLP, ......, hated, that, movie]
```

        其次，需要提取该推文的特征，提取特征过程如下：先对每个推文定义一个跟字典长度一样长的数组，这个数组**初始化为0**；之后按照单词维度**遍历该推文**内容，按需将单词出现在字典中的位置的数组**下标设置为1**，没出现的位置的内容自然就是为0。

```textile
举个例子：延续上个例子中：I am happy because I am learning NLP;
这个推文提取完成的特征向量可以表示为 |V| = [1, 1, 1, 1, 1, 1, ......, 0, 0, 0]
```

        **综合第一步的过程来看**：想要去通过LR分类器(逻辑回归分类器)来得出该推文的情感标签，那么**需要先将推文转化为向量**，然后将该向量投入到分类器中，所以**LR分类器的输入特征的长度是n。**

> 　    但是从上文中也能**提出两个问题**：每个推文的特征向量都跟一个字典一样长，那么如果一组推文数量很大，那么每个特征向量（推文的向量表示）都是稀疏表示，如果把这个投入到LR分类器中进行训练，**那么该LR分类器的训练时间岂不是非常的长**？那么由此得出的预测时间岂不是非常的大，**远远超过实际得出预测的时间**？带着这些问题继续往下文看。

        **2、第二步：在表示推文向量的方法层面，来降低代表推文向量的长度**：

        为什么说是从代表推文向量的方法层面？这个问题先暂时不考虑，等看到后文的时候就自然而然明白了。

        那么继续考虑如果解决第一步所提出的问题？首先，需要能**够创建频率字典**（frequency dictionary），**目的是能够通过frequency dictionary去表示每个推文**，而不是通过上面长度为n的向量来表示推文。创建过程如下：① 首先你有一组已经分好情感类（好坏两类）的正确的语料库，比如我们的集合标签Y；② 还是一样，先按照单词维度来遍历整组推文（语料库），列出所有单词；**③ 先拿好的情感来说，依次统计所列每个单词在这个预料库中出现了几次**，那么**这个单词出现的次数就可以理解为该单词出现在好的情感这一类下的频率**；对坏的情感类同理，也是对同样的所列单词做统计；得出所有单词在坏类下出现的频率；组合在一起就可以得出频率词典。

```textile
举个例子：我有一组已经正确的分好情感类的语料库，其中有四组推文;
好的情感两句：I am happy because I am learning NLP; I am happy。
坏的情感两句：I am sad, I am not learning NLP; I am sad。
首先分析PosFreq："I"在好的一类的两句话中总共出现了3次，所以这里是3。之后的依次类推，能得出整个frequency dictionary。
由此得出频率词典：
```

| Vocabulary | PosFreq (1) | NegFreq (0) |
| ---------- |:----------- | ----------- |
| I          | 3           | 3           |
| am         | 3           | 3           |
| happy      | 2           | 0           |
| because    | 1           | 0           |
| learning   | 1           | 1           |
| NLP        | 1           | 1           |
| sad        | 0           | 2           |
| not        | 0           | 1           |

        其次，通过上面刚创建好的频率字典，**创建一个更简单的3维的特征向量来代替之前所用的V维的推文向量**；这样可以大幅度节省LR分类器的运行时间。这个特征向量的运算是这样的：

$$
[1, \Sigma freqs(w, 1), \Sigma freqs(w, 0)]
$$

        解读该三维向量：第一位：**表示一个偏差值**（也称为偏置项或者截距项），一般固定为1。原因是：逻辑回归中的假设函数通常表示为 **$h_\theta(x) = \theta_0 + \theta_1x_1 + \theta_2x_2 + ···+ \theta_nx_n$**，而加上1，这样相乘就可以保留 $\theta_0$ 的值，这样就允许模型有正常的偏差，可以更好的拟合数据。第二位：表示这个推文中的每个单词在频率字典中表示**好的一列的频率之和**；第三位：是推文中每个单词在频率字典中**坏的一列的频率之和**。通过这三个特征的计算就表示出了这个推文的三维特征表示。

综合上述两个步骤，就可以简化之前的V维向量来进行LR分类处理，节约了运算时间，也能够将真实的预测时间缩短到实际需要的预测时间。

        **3、第三步：在推文的内容层面，来降低代表推文的向量的长度**

        为什么这里说是从推文的内容上来简化推文向量的长度？理解一下这句话的意思：**一个推文（一段话）所表达的含义，理解起来并不需要用到这句话中的每个单词**。很好理解，比如：“哇，这个地方真的很美；并且，你在我心里也很美”，那么这句话所表达的意思简化出来是不是：“地方美，你美”。这个例子是不是典型的积极情绪的一个句子，那么上文19个字组成的句子所表达的意思是不是值用5个字就能搞定？但是可能又有人问：为什么上面例子可以这样替换，我逻辑回归分类器不就是能够在面对无论是复杂句子还是简单句子都可以分辨出情感的类别吗？经过你这个处理，不相当于复杂的句子都变成了简单的句子了？其实这个问题很好解答：因为我们LR分类器最主要的目的就是为了能够分出句子的情感类别，而不是学习更多知识的。所以如果在处理完句子内容的基础上，再加上上文第二步所用的三维推文向量表示，是不是能在可控范围内大幅降低模型训练所需时间成本？

        **可控范围内降低推文长度但不改变推文大致意思的方法 —— 预处理（preprocess）**

        **预处理的过程大致可以分为5个步骤，最后预处理的结果是一个单词数组：① 删除用户信息和URL；② 删除一些标点符号（这个是可选的，如果标点符号对表达意思有影响可以不用删除该标点符号）；③ 删除停顿词（连接词等：and, but, or这种）；④ 把每个单词转化为词根（比如：dancer, dancing, danced变成danc）；⑤ 把每个单词都变成小写**。每个模型预处理的过程包括但不限于这五个步骤，具体情况还得根据具体的业务需求来处理。因为预处理会对推文的内容上进行修改，所以也可以通过此操作来间接缩短频率字典的大小，所以**一般预处理都是在创建频率字典之前**！

```textile
举个例子：“@Pfeiffer and @Jerry are tuning a GREAT AI model at https://deeplearning.ai!!! ”；
经过第一步变成了：[and, are, tuning, a, GREAT, AI, model, at, !!!]；
经过第二步变成了[and, are, tuning, a, GREAT, AI, model, at]；
经过第三步变成了[tuning, GREAT, AI, model]；
经过第四步变成了[tun, GREAT, AI, model]；
经过第五步就变成了[tun, great, ai, model]。
```

        这个例子我用代码生成了一个非正式函数的处理过程，python文件为preprocess.py，可以大致参考一下！！！

        并且我在build_frequency_dictionary.py文件中，演示了，完整的从推文的预处理，到创建频率字典，到最后可视化展示的完整示例！！！

        到目前为止，数据X的准备工作也就处理完成，我们完成了第一步，也就是从数据X到Sigmod函数的一个过程，那么接下来我们继续沿着监督式机器学习方向走！！！

        **4、第四步：研究Sigmod函数 -- LR分类器的模型**

$$
h(x^{(i)}, \theta) = \frac{1}{1+e^{-\theta^Tx^{(i)}}}
$$

        首先，我们给出Sigmod函数的数学表达式，我们来分析一下函数的性质：整个函数最主要的就是分母上的这一组$\theta^Tx^{(i)}$，这个是我们传入处理好的数据x与给定的参数$\theta$之间的**点积**（如果点积不太懂得自行百度）。

        其次我们了解一下e的函数的特点是：①它的次方如果趋向于正无穷，那么这个函数是无穷大的，且是正无穷大；②它的次方如果是趋向于负无穷的，那么这个函数是趋向于0的；③这个函数无论是什么次方，这个函数的值永远是大于0的；④指数函数如果是0次方，那么指数函数的值为1。

        最后，我们再来看一下这个$h(x^{(i)}, \theta)$函数，如果$\theta^Tx^{(i)}$的点积为0，整体$h(x^{(i)}, \theta)$函数就是0.5；如果$\theta^Tx^{(i)}$的点积大于0，整体$h(x^{(i)}, \theta)$函数就是大于0.5，也就可以表示积极的情感；如果$\theta^Tx^{(i)}$的点积小于0，整体$h(x^{(i)}, \theta)$函数就是小于0.5，也就可以表示消极的情感。

```textile
针对这句话：@YMourri and @AndrewYNg are tuning a GREAT AI model
如果在频率字典中得出的特征是：[1, 3746, 245]；
之后给出的参数theta是[0.00003, 0.00150, -0.00120]；（先不管此处的参数是怎么得来的）
得出的点积的结果约为4.92；
那么很明显的表示出这句话是好的情感。
```

        **5、第五步：如何得出参数$\theta$**

        









未完待续
