# 监督式机器学习 之 逻辑回归算法（Logistic Regression Algorithm of Supervised Marching Learning）

## 一、整体的理解

        首先，在监督式机器学习中，你有**两个输入**：输入特征集合X 和 标签集合Y。**标签集合Y**可以理解为：它是在你的输入数据的基础上完全准确的预测结果；此有两个特点：第一在你数据的基础上的预测；第二是完全准确的。在监督式机器学习中，我们不对标签集合Y做任何处理，它的任务就是一个 ——“标杆”。**输入特征集合X**可以理解为：就是你的处理数据。

        其次整体的监督式机器学习的过程就是：首先**拿到特征集合X**，然后把特征集合X**投入到预测函数**（prediction function）中运行，在运行过程中我们需要**投入输入参数 $Θ$**，最终也就**获得了模型的预测集合ÿ**，然后用开销函数（cost function）**对比预测集合ÿ与标签集合Y之间的差异**。这个预测函数的处理过程就是我们的模型处理过程。要想我们的模型的效果不错，需要**对我们的参数进行调整，然后重复上述步骤**，直到得出这个差异的最小值，最后就得到了最佳的模型。这里我们画个图加深理解：

![supervised machine learning process](../images/supervised%20machine%20learning%20process.jpg)

## 二、用逻辑回归算法去做情感分类用例来演示该监督学习

    首先定义几个点：

        1、首先目标是预测出一组推文中每个推文的情感状态；

        2、情感只包括两个方面：积极方面和消极方面，积极方面的设置为1，消极方面的设置为0；

        3、所以我们首先需要获取输入特征集合X，也就是获取特征，然后在设置参数来一同执行prediction function，然后再执行cost function得出差异，然后不断调参，循环过程，得到最终的模型，也就是逻辑回归分类器。这里是二分类。

## 三、监督学习中的具体实现？

        对逻辑回归分类器（logistic regression classifier）来做情感分析的例子来说：

        1、**第一步：计算机如何能够处理推文？**—— 把推文转化为向量的形式

            首先，你需要**创建一个字典**，这个字典一定包含以下几个**特点**：① 这个字典内容的**维度**是限定在：一个单词；② 这个字典中每个单词是**不可重复**的；③ 这个词典包含这**一组推文**中**所有的**不重复的单词。

　　         举个例子：一组推文：I am happy because I am learning NLP; ......; I hated that movie。这组推文中的字典 V = [I, am, happy, because, learning, NLP, ......, hated, that, movie]

        其次，需要提取该推文的特征，提取特征过程如下：先对每个推文定义一个跟字典长度一样长的数组，这个数组**初始化为0**；之后按照单词维度**遍历该推文**内容，按需将单词出现在字典中的位置的数组**下标设置为1**，没出现的位置的内容自然就是为0。

                举个例子：延续上个例子中：I am happy because I am learning NLP，这个推文提取完成的特征向量可以表示为 |V| = [1, 1, 1, 1, 1, 1, ......, 0, 0, 0]

        **综合第一步的过程来看**：想要去通过LR分类器(逻辑回归分类器)来得出该推文的情感，那么**需要先将推文转化为向量**，然后将该向量投入到分类器中，所以**LR分类器的输入特征的长度是n。**

　    但是从上文中也能**提出两个问题**：每个推文的特征向量都跟一个字典一样长，那么如果一组推文很大，那么每个特征向量（推文的向量表示）都是稀疏表示，如果把这个投入到LR分类器中进行训练，**那么该LR分类器的训练时间岂不是非常的长**？那么由此得出的预测时间岂不是非常的大，**远远超过实际得出预测的时间**？带着这些问题继续往下文看。

        2、第二步：改进第一步的每个推文的长度，由此解决上述两个问题：

　　 首先，需要能**够创建频率字典**（frequency dictionary），**目的是能够通过frequency dictionary去表示每个推文**，而不是通过上面长度为n的向量来表示推文。创建过程如下：① 首先你有一组已经分好情感类（好坏两类）的正确的语料库；② 还是一样，先按照单词维度来**遍历整组推文（语料库），列出所有单词；**③ 先拿好的情感来说，依次统计所列所有单词在这个预料库中出现了几次，那么**这个单词出现的次数就可以理解为该单词出现在好的情感这一类下的频率**；对坏的情感类同理，也是对同样的所列单词做统计；得出所有单词在坏类下出现的频率；组合在一起就可以得出频率词典。

　　　　举个例子：我有一组已经正确的分好情感类的语料库，其中有四组推文，好的情感两句：I am happy because I am learning NLP; I am happy。坏的情感两句：I am sad, I am not learning NLP; I am sad。由此得出频率词典：

　　　　首先分析PosFreq："I"在好的一类的两句话中总共出现了3次，所以这里是3，依次类推，能得出整个frequency dictionary。

                                                    | Vocabulary | PosFreq (1) | NegFreq (0) |
                                                    | ---------- | ----------- | ----------- |
                                                    | I          | 3           | 3           |
                                                    | am         | 3           | 3           |
                                                    | happy      | 2           | 0           |
                                                    | because    | 1           | 0           |
                                                    | learning   | 1           | 1           |
                                                    | NLP        | 1           | 1           |
                                                    | sad        | 0           | 2           |
                                                    | not        | 0           | 1           |
